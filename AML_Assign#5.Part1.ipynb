{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d42ce08b-e5b0-4ab5-aec5-fc91624384c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9248b9c-930b-4409-8121-a3f900e449be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92530ca8-52e0-4f59-ac6f-59e248d475bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for Tiny ImageNet dataset\n",
    "data_dir = \"tiny-imagenet-200\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dead853-f7a3-486e-b109-dcbc92eef2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations with augmentation for training and resizing for validation\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(299),  # Resizing to 299 for Inception compatibility\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),  # Resizing to 299 for Inception compatibility\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4a4fdf7-fd27-4470-be13-4bb277303029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'val')\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec1d967c-27c5-4135-8686-1419555bb339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the training and validation datasets\n",
    "train_subset_indices = np.random.choice(len(train_dataset), 20000, replace=False)\n",
    "val_subset_indices = np.random.choice(len(val_dataset), 500, replace=False)\n",
    "\n",
    "train_subset = Subset(train_dataset, train_subset_indices)\n",
    "val_subset = Subset(val_dataset, val_subset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fa394e4-aea8-43e6-bd36-00f0260abc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_subset, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6979793-3009-4bc1-a360-3e9878db2d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training subset data: 20000 images\n",
      "Validation data: 500 images\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training subset data: {len(train_subset)} images\")\n",
    "print(f\"Validation data: {len(val_subset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f740f54e-fc89-41ad-a28c-940a040333ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93d1ff38-4006-4dff-b7b3-50e132e995fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to initialize pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4505aab8-b150-4d91-a594-fe4f6281bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name):\n",
    "    if model_name == \"VGG-19\":\n",
    "        model = models.vgg19(weights=\"IMAGENET1K_V1\")\n",
    "        model.classifier[6] = nn.Linear(4096, 200)\n",
    "    elif model_name == \"ResNet50V2\":\n",
    "        model = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "        model.fc = nn.Linear(model.fc.in_features, 200)\n",
    "    elif model_name == \"InceptionV4\":\n",
    "        model = models.inception_v3(weights=\"IMAGENET1K_V1\", aux_logits=True)  # Use InceptionV3 with aux_logits\n",
    "        model.fc = nn.Linear(model.fc.in_features, 200)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17cef2d2-b1d3-4fea-a81d-994eb968f8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97455d1f-75ca-4473-b157-7e14b1e68a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, data_loader, optimizer, criterion, device, is_inception=False):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for images, labels in tqdm(data_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Handle auxiliary outputs if using Inception\n",
    "        if is_inception:\n",
    "            outputs, aux_outputs = model(images)\n",
    "            loss = criterion(outputs, labels) + 0.4 * criterion(aux_outputs, labels)\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    return running_loss / len(data_loader), 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca1a6141-21ac-477b-9138-39c14eba1f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data_loader, criterion, device, is_inception=False):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Handle auxiliary outputs if using Inception and the model is in training mode\n",
    "            if is_inception and model.training:\n",
    "                outputs, _ = model(images)  # Only use the primary output during validation\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "                \n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "    return running_loss / len(data_loader), 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f20608-6335-4501-9bf2-da75bb4da15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fed108d-bd9b-4c8a-a3a1-70485413fe26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "519baa4c-b542-47a9-bc05-fa2ab1c43c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function with early stopping\n",
    "def train_model(model_name, num_epochs=5):\n",
    "    print(f\"\\nTraining {model_name} Model\")\n",
    "    \n",
    "    model = initialize_model(model_name).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    early_stopping = EarlyStopping(patience=3, min_delta=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Check if Inception model\n",
    "    is_inception = model_name == \"InceptionV4\"\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device, is_inception)\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device, is_inception)\n",
    "        \n",
    "        print(f\"{model_name} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping triggered for {model_name}.\")\n",
    "            break\n",
    "        \n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "476ce1b9-bb50-4812-baa2-8a602b843ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "164bd227-0046-4d76-a7fe-b7c48dc505f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0de61ae9-0079-4c2e-a8a4-c7d75e601ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training VGG-19 Model\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [05:17<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG-19 - Train Loss: 5.2668, Train Acc: 0.72%, Val Loss: 5.9807, Val Acc: 0.00%\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [05:20<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG-19 - Train Loss: 5.1684, Train Acc: 1.26%, Val Loss: 5.3421, Val Acc: 7.00%\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [05:19<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG-19 - Train Loss: 5.1042, Train Acc: 1.67%, Val Loss: 6.0315, Val Acc: 3.40%\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [05:19<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG-19 - Train Loss: 5.0254, Train Acc: 2.04%, Val Loss: 5.6076, Val Acc: 4.00%\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [05:20<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG-19 - Train Loss: 4.9434, Train Acc: 2.69%, Val Loss: 6.4141, Val Acc: 1.80%\n",
      "Early stopping triggered for VGG-19.\n"
     ]
    }
   ],
   "source": [
    "train_model(\"VGG-19\", num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94ca53fb-0e58-409f-99cc-773448fed738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ResNet50V2 Model\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [03:19<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50V2 - Train Loss: 5.0408, Train Acc: 2.71%, Val Loss: 6.3206, Val Acc: 0.40%\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [03:20<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50V2 - Train Loss: 4.4077, Train Acc: 8.05%, Val Loss: 6.8622, Val Acc: 1.40%\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [03:20<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50V2 - Train Loss: 4.0439, Train Acc: 12.63%, Val Loss: 8.0913, Val Acc: 0.40%\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [03:21<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50V2 - Train Loss: 3.7441, Train Acc: 17.21%, Val Loss: 9.2060, Val Acc: 1.00%\n",
      "Early stopping triggered for ResNet50V2.\n"
     ]
    }
   ],
   "source": [
    "train_model(\"ResNet50V2\", num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "287a055c-60f6-4f05-9672-477124aed207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training InceptionV4 Model\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [02:07<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV4 - Train Loss: 6.8252, Train Acc: 4.00%, Val Loss: 7.2661, Val Acc: 0.20%\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [02:06<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV4 - Train Loss: 5.5884, Train Acc: 12.71%, Val Loss: 8.1489, Val Acc: 0.60%\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [02:06<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV4 - Train Loss: 4.8353, Train Acc: 21.11%, Val Loss: 9.2087, Val Acc: 0.40%\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [02:06<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV4 - Train Loss: 4.1623, Train Acc: 29.81%, Val Loss: 9.8372, Val Acc: 1.20%\n",
      "Early stopping triggered for InceptionV4.\n"
     ]
    }
   ],
   "source": [
    "train_model(\"InceptionV4\", num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14544abd-9e0e-4015-8c17-56bd7cd33fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming test data is stored in a directory named 'test' inside tiny-imagenet-200\n",
    "test_dir = os.path.join(data_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f2512ca-84bf-4325-b836-34d038717331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation for test data (same as validation transformations, no data augmentation)\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),  # Resizing to 299 for Inception compatibility\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b12ba72-6fd8-4dd8-acd2-72e98ad1fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb2e54a4-dba2-4366-b990-db0209c8a4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data: 10000 images\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test data: {len(test_dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0172b5f-d9ee-4773-97cf-fbb889ffa038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "def test(model, data_loader, criterion, device, is_inception=False):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():  # No gradients needed for testing\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Handle auxiliary outputs only if using Inception in training mode\n",
    "            if is_inception and model.training:\n",
    "                outputs, _ = model(images)  # Use both outputs only in training mode\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "                \n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "    avg_loss = running_loss / len(data_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0535812-b3e1-40db-a399-b7b11ad17f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test each trained model\n",
    "def evaluate_on_test_set(model_name):\n",
    "    model = initialize_model(model_name).to(device)\n",
    "    # If you saved model checkpoints, load them here:\n",
    "    # model.load_state_dict(torch.load(f\"{model_name}_best_model.pth\"))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    is_inception = model_name == \"InceptionV4\"\n",
    "    test_loss, test_acc = test(model, test_loader, criterion, device, is_inception)\n",
    "    print(f\"{model_name} - Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb2ff4e1-8d85-4618-af6e-ab909bf3848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG-19 - Test Loss: 5.2231, Test Acc: 0.23%\n",
      "ResNet50V2 - Test Loss: 5.3685, Test Acc: 0.00%\n",
      "InceptionV4 - Test Loss: 5.2444, Test Acc: 0.06%\n"
     ]
    }
   ],
   "source": [
    "# Example of calling evaluate_on_test_set for each model after training\n",
    "evaluate_on_test_set(\"VGG-19\")\n",
    "evaluate_on_test_set(\"ResNet50V2\")\n",
    "evaluate_on_test_set(\"InceptionV4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea086a-47f4-4741-866c-be2da6f7a5de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b63b4d-3ee5-4e7d-827e-0f1b2c056bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
